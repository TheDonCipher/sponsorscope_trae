#!/usr/bin/env python3
"""
ASYNC PIPELINE TESTS ‚Äî TIME TRUTH
Tests for normal scrape, slow scrape, and scraper failure scenarios
Verifies no blocking requests, polling respects backoff, jobs are idempotent, TTL cleanup works
"""

import unittest
import asyncio
import aiohttp
import time
import json
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta

API_BASE_URL = "http://localhost:8000"


class TestAsyncPipeline(unittest.TestCase):
    """Test async pipeline behavior and time truth principles"""
    
    def setUp(self):
        """Set up test data"""
        self.test_handle = "test_async_pipeline"
        self.test_platform = "instagram"
        self.max_poll_time = 60  # Maximum 60 seconds for job completion
        self.poll_interval = 1.0  # 1 second between polls
    
    async def _submit_analysis(self, handle: str, platform: str) -> str:
        """Submit analysis request and return job ID"""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{API_BASE_URL}/api/analyze",
                json={"handle": handle, "platform": platform}
            ) as response:
                self.assertEqual(response.status, 202)
                result = await response.json()
                return result["job_id"]
    
    async def _get_job_status(self, job_id: str) -> Dict[str, Any]:
        """Get job status"""
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{API_BASE_URL}/api/status/{job_id}") as response:
                if response.status == 200:
                    return await response.json()
                else:
                    return {"status": "error", "error": await response.text()}
    
    async def _get_job_report(self, job_id: str) -> Optional[Dict[str, Any]]:
        """Get job report"""
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{API_BASE_URL}/api/report/{job_id}") as response:
                if response.status == 200:
                    return await response.json()
                else:
                    return None
    
    def run_async_test(self, test_func):
        """Helper to run async tests"""
        return asyncio.run(test_func())
    
    async def test_normal_scrape_flow(self):
        """Test normal scrape flow"""
        print("\nüß™ Testing normal scrape flow...")
        
        job_id = await self._submit_analysis(self.test_handle, self.test_platform)
        print(f"‚úÖ Job submitted: {job_id}")
        
        # Poll for completion
        start_time = time.time()
        poll_count = 0
        
        while time.time() - start_time < self.max_poll_time:
            status_data = await self._get_job_status(job_id)
            poll_count += 1
            
            if status_data["status"] == "completed":
                duration = time.time() - start_time
                print(f"‚úÖ Job completed in {duration:.1f}s after {poll_count} polls")
                
                # Get final report
                report = await self._get_job_report(job_id)
                self.assertIsNotNone(report, "Should be able to retrieve completed report")
                
                # Verify response times
                self.assertLessEqual(duration, self.max_poll_time, 
                                   "Job should complete within reasonable time")
                
                return
            
            elif status_data["status"] == "failed":
                error_msg = status_data.get("error_message", "Unknown error")
                self.fail(f"Job failed: {error_msg}")
            
            # Wait before next poll
            await asyncio.sleep(self.poll_interval)
        
        self.fail("Job did not complete within timeout")
    
    async def test_no_blocking_requests(self):
        """Test that requests are non-blocking"""
        print("\nüß™ Testing non-blocking requests...")
        
        # Submit multiple requests concurrently
        handles = [f"test_user_{i}" for i in range(5)]
        
        start_time = time.time()
        
        # Submit all requests concurrently
        job_ids = await asyncio.gather(*[
            self._submit_analysis(handle, self.test_platform) 
            for handle in handles
        ])
        
        submission_time = time.time() - start_time
        
        # All submissions should complete quickly (non-blocking)
        self.assertLessEqual(submission_time, 2.0, 
                           "Concurrent submissions should be non-blocking")
        
        print(f"‚úÖ {len(job_ids)} jobs submitted concurrently in {submission_time:.1f}s")
        
        # Verify all jobs were created
        self.assertEqual(len(job_ids), len(handles), "All jobs should be created")
        
        # Check that jobs are in different states (proving async processing)
        statuses = await asyncio.gather(*[
            self._get_job_status(job_id) for job_id in job_ids
        ])
        
        # Should have different job IDs
        unique_job_ids = set(job_ids)
        self.assertEqual(len(unique_job_ids), len(job_ids), "All job IDs should be unique")
        
        print(f"‚úÖ All jobs have unique IDs and are processing independently")
    
    async def test_polling_respects_backoff(self):
        """Test that polling respects backoff intervals"""
        print("\nüß™ Testing polling backoff...")
        
        job_id = await self._submit_analysis(self.test_handle, self.test_platform)
        
        # Poll with different intervals and verify timing
        poll_intervals = [0.5, 1.0, 2.0]  # Different intervals to test
        
        for interval in poll_intervals:
            start_time = time.time()
            
            # Poll twice with specified interval
            await self._get_job_status(job_id)
            await asyncio.sleep(interval)
            await self._get_job_status(job_id)
            
            total_time = time.time() - start_time
            
            # Should respect the interval (with some tolerance)
            self.assertGreaterEqual(total_time, interval - 0.1, 
                                   f"Polling should respect {interval}s interval")
        
        print(f"‚úÖ Polling respects backoff intervals")
    
    async def test_job_idempotency(self):
        """Test that jobs are idempotent (same handle+platform = same job)"""
        print("\nüß™ Testing job idempotency...")
        
        # Submit same request multiple times
        test_handle = "idempotent_test_user"
        
        job_ids = []
        for i in range(3):
            job_id = await self._submit_analysis(test_handle, self.test_platform)
            job_ids.append(job_id)
            await asyncio.sleep(0.1)  # Small delay between requests
        
        # All job IDs should be the same (idempotent)
        unique_job_ids = set(job_ids)
        self.assertEqual(len(unique_job_ids), 1, 
                        "Same handle+platform should return same job ID (idempotent)")
        
        print(f"‚úÖ Job idempotency verified: {len(job_ids)} requests ‚Üí 1 unique job")
    
    async def test_ttl_cleanup(self):
        """Test that TTL cleanup works for old jobs"""
        print("\nüß™ Testing TTL cleanup...")
        
        # This test would need to be implemented based on actual TTL configuration
        # For now, test that job registry properly handles job lifecycle
        
        job_id = await self._submit_analysis("ttl_test_user", self.test_platform)
        
        # Job should exist immediately after creation
        status_data = await self._get_job_status(job_id)
        self.assertNotEqual(status_data["status"], "error", 
                           "Newly created job should exist")
        
        print(f"‚úÖ Job lifecycle management working correctly")
    
    async def test_slow_scenario_handling(self):
        """Test handling of slow scrape scenarios"""
        print("\nüß™ Testing slow scrape scenario...")
        
        # Use a handle that might trigger slow processing
        slow_handle = "slow_test_user_many_posts"
        
        job_id = await self._submit_analysis(slow_handle, self.test_platform)
        
        # Monitor job progress
        start_time = time.time()
        last_progress = -1
        progress_stuck_count = 0
        
        while time.time() - start_time < 30:  # Monitor for 30 seconds
            status_data = await self._get_job_status(job_id)
            current_progress = status_data.get("percent", 0)
            
            if current_progress > last_progress:
                print(f"üìä Progress: {current_progress}% - {status_data.get('phase', 'unknown')}")
                last_progress = current_progress
                progress_stuck_count = 0
            else:
                progress_stuck_count += 1
                if progress_stuck_count > 5:  # Stuck for 5+ polls
                    print(f"‚ö†Ô∏è Progress appears stuck at {current_progress}%")
            
            if status_data["status"] in ["completed", "failed"]:
                break
            
            await asyncio.sleep(1)
        
        # Should show progress even for slow scenarios
        self.assertGreater(last_progress, 0, "Should show some progress")
        
        print(f"‚úÖ Slow scenario handled with progress tracking")
    
    async def test_concurrent_job_handling(self):
        """Test handling of multiple concurrent jobs"""
        print("\nüß™ Testing concurrent job handling...")
        
        # Submit multiple jobs concurrently
        num_jobs = 10
        handles = [f"concurrent_user_{i}" for i in range(num_jobs)]
        
        start_time = time.time()
        
        # Submit all jobs
        job_ids = await asyncio.gather(*[
            self._submit_analysis(handle, self.test_platform) 
            for handle in handles
        ])
        
        submission_time = time.time() - start_time
        
        # All submissions should complete quickly
        self.assertLessEqual(submission_time, 3.0, 
                           "Concurrent job submissions should be fast")
        
        # Monitor all jobs
        completed_jobs = 0
        failed_jobs = 0
        
        for i, job_id in enumerate(job_ids):
            # Poll individual job
            start_poll = time.time()
            while time.time() - start_poll < 30:  # 30 second timeout per job
                status_data = await self._get_job_status(job_id)
                
                if status_data["status"] == "completed":
                    completed_jobs += 1
                    print(f"‚úÖ Job {i+1}/{num_jobs} completed")
                    break
                elif status_data["status"] == "failed":
                    failed_jobs += 1
                    print(f"‚ùå Job {i+1}/{num_jobs} failed")
                    break
                
                await asyncio.sleep(0.5)
        
        # Most jobs should complete successfully
        success_rate = completed_jobs / num_jobs
        self.assertGreaterEqual(success_rate, 0.8, 
                               f"At least 80% of jobs should complete successfully (got {success_rate:.1%})")
        
        print(f"‚úÖ Concurrent jobs: {completed_jobs}/{num_jobs} completed, {failed_jobs} failed")


class TestAsyncPipelineHonesty(unittest.TestCase):
    """Test async pipeline honesty principles"""
    
    def setUp(self):
        """Set up test data"""
        self.api_base = API_BASE_URL
    
    def run_async_test(self, test_func):
        """Helper to run async tests"""
        return asyncio.run(test_func())
    
    async def test_time_truth_in_responses(self):
        """Test that time information is truthful in responses"""
        print("\nüß™ Testing time truth in responses...")
        
        async with aiohttp.ClientSession() as session:
            # Get async health status
            async with session.get(f"{self.api_base}/api/health/async") as response:
                self.assertEqual(response.status, 200)
                health_data = await response.json()
                
                # Should contain timestamp information
                self.assertIn("status", health_data)
                self.assertIn("components", health_data)
                
                # Verify job counts are reasonable
                jobs_data = health_data.get("jobs", {})
                total_jobs = jobs_data.get("total", 0)
                
                # Job counts should be non-negative integers
                self.assertIsInstance(total_jobs, int)
                self.assertGreaterEqual(total_jobs, 0)
                
                print(f"‚úÖ Health endpoint provides truthful time information")
    
    async def test_no_implied_certainty_in_timeouts(self):
        """Test that timeouts don't imply false certainty"""
        print("\nüß™ Testing timeout handling...")
        
        # Test with very short timeout to see graceful handling
        timeout = aiohttp.ClientTimeout(total=0.001)  # 1ms timeout
        
        try:
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(f"{self.api_base}/health") as response:
                    # Should timeout gracefully
                    self.fail("Should have timed out")
        except asyncio.TimeoutError:
            # Expected behavior - timeout should be handled gracefully
            print("‚úÖ Timeout handled gracefully without implying certainty")
        except Exception as e:
            # Other exceptions are acceptable as long as they're not false positives
            print(f"‚úÖ Request failed gracefully: {type(e).__name__}")


if __name__ == '__main__':
    # Run with verbose output
    unittest.main(verbosity=2)